{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checpoint='distilbert-base-uncased'\n",
    "## define label maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label={0:\"Negative\",1:\"Positive\"}\n",
    "label2id={\"Negative\":0,\"Positive\":1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating classification model from model_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AutoModelForSequenceClassification.from_pretrained(model_checpoint,num_labels=2,id2label=id2label,label2id=label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_dataset(\"shawnn/imdb-trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(model_checpoint,add_prefix_space=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create tokenize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    text=example(text)\n",
    "    tokenizer.truncation_side=\"left\"\n",
    "    tokenized_input=tokenizer(text,return_tensors=\"np\",truncation=True,max_length=512)\n",
    "    return tokenized_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=evaluate.load(\"accuracy\")\n",
    "\n",
    "## defining an evaluating function to pass into trainer later\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions,labels=p\n",
    "    predictions=np.argmax(predictions,axis=1)\n",
    "    return {\"accuracy\":accuracy.compute(predictions=predictions,refernce=labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining a list of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list=[\"It was not good\",\"Not a fan, don't recomend\"]\n",
    "for text in text_list:\n",
    "    inputs=tokenizer.encode(text,return_tensors='pt')\n",
    "    logits=model(inputs).logits\n",
    "    ## convert logist to labels\n",
    "    prediction=torch.argmax(logits)\n",
    "    print(text+\"-\"+id2label[prediction.tolist()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lora configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pefit_config=LoraConfig(task_type=\"SEQ_CLS\",r=4,lora_alpha=32,  lora_dropout=0.01,target_modules=['q_lin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "batch_size=4\n",
    "num_epochs=10\n",
    "training_args=TrainingArguments(output_dir=model_checkpoint+\"lora-text-classification\",learning_rate=lr,per_device_train_batch_size=batch_size,num_train_epochs=num_epochs,weight_decay=0.01,evaluation_stratergy=\"epoch\",save_stratergy=\"epoch\",load_best_model_at_end=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'peter'), (5, 'peter')]\n"
     ]
    }
   ],
   "source": [
    " a=[(1, \"peter\"), (3, \"Sam\"), (5, \"peter\")]\n",
    " res=[ele for ele in a if ele[1]==\"peter\"]\n",
    " print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m middle_elements\n\u001b[0;32m      8\u001b[0m nested_tuples \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m), (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m), (\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m))\n\u001b[1;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mget_middle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnested_tuples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[1;32mIn[19], line 6\u001b[0m, in \u001b[0;36mget_middle\u001b[1;34m(l1)\u001b[0m\n\u001b[0;32m      4\u001b[0m     middles\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(ele)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      5\u001b[0m     element\u001b[38;5;241m=\u001b[39mele[middles]\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mmiddle_elements\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(element)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m middle_elements\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "def get_middle(l1):\n",
    "    middle_element=[]\n",
    "    for ele in l1:\n",
    "        middles=len(ele)//2\n",
    "        element=ele[middles]\n",
    "        middle_elements.append(element)\n",
    "    return middle_elements\n",
    "nested_tuples = ((1, 2, 3), (4, 5, 6), (7, 8, 9))\n",
    "result = get_middle(nested_tuples)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creater Trainer Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(model=model,args=training_args,train_dataset=tokenize_dataset[\"train\"],eval_dataset=tokenized_dataset[\"validation\"],tokenizer=tokenizer,data_collator=data_collator,compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
