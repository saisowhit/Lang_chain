{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock=boto3.client(service_name=\"bedrock-runtime\",region_name=\"us-east-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_llm():\n",
    "    llm=Bedrock(model_id=\"meta_\",client=bedrock,model_kwards={\"max_gen_len\":2})\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_llm(llm,query):\n",
    "    prompt_template=\"\"\"\n",
    "    <s> [INST] You are helpful, respectiful and honest. {question}[/INST]</>\n",
    "    \"\"\"\n",
    "    Prompt=PromptTemplate(template=prompt_template,input_variable=[\"questions\"])\n",
    "    chain=LLMChain(llm=llm,prompt=prompt)\n",
    "    return chain.run(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_handler(event,context):\n",
    "    user_question=event.get(\"question\")\n",
    "    llm=get_llama_llm()\n",
    "    response=get_response_llm(llm,user_question)\n",
    "    print(\"response\",response)\n",
    "    return {'body':response,\"statusCode\":200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create layers in aws lambda to run all the dependecies. We have to prepare the zip files. we can do it through docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run \n",
    "# pip install langchain langchain_community -t ./python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inside docker image to zip\n",
    "zip -r my_lambda_layer.zip python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the layer to the lambda code"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
