{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ=os.getenv(OPEN_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex,SimpleDirectoryReader\n",
    "document=SimpleDirectoryReader(\"data\").load_data()\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=VectorStoreIndex.from_documents(document,show_progress=True) ## converting document to Index\n",
    "## show_progress gives progress on each and every task\n",
    "index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using index we can query any question that we want to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine=index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=query_engine.query(\"What is Transformers\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.response.pprint_utils import pprint_response\n",
    "pprint_response(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.indices.postprocessor import SimilarityPostProcessor\n",
    "retriever=VectorIndexRetriever(index=index,similarity_top_k=4)\n",
    "query_engine=RetrieverQueryEngine(retriever=retriever)\n",
    "query_engine=index.as_query_engine()\n",
    "response=query_engine.query(\"What is the attention that you need\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Similarity Postprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if similarity greater than 80 it will give the results out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor=SimilarityPostProcessor(similarity_cutoff=0.80)\n",
    "query_engine=RetrieverQueryEngine(retriever=retriever,node_postprocessor=[postprocessor])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To store index inside the harddisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (VectorStoreIndex,SimpleDirectoryReader,StorageContext,load_index_from_storage)\n",
    "PERSITS_DIR=\"./storage\"\n",
    "if not os.path.exists(PERSITS_DIR):\n",
    "    ## load the documets and create the index\n",
    "    documents=SimpleDirectoryReader(\"data\").load_data()\n",
    "    index=VectorIndex.from_documents(documents)\n",
    "    index.storage_context.persist(persist_dir=PERSITS_DIR)\n",
    "else: ## load the exisitng index\n",
    "    storage_context=StorageContext.from_defaults(persist_dir=PERSITS_DIR)\n",
    "    index=load_index_from_storage(storage_context)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
