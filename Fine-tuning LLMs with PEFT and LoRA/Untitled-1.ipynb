{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingace_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SETUP THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "from transfomers import AutoTokenizer,AutoConfig,AutoModelForCasualLM\n",
    "model=AutoModelForCasualLM.from_pretrained('bigscienc',load_in_8bit=True,device_map='auto')\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"bigscience/bloom-7bl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Freezing the original weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "    if param.ndim==1:\n",
    "        param.data=param.data.to(torch.float32)\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_False()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CastOutputToFloat(nn.Sequential):\n",
    "    def forward(self,x):\n",
    "        return super().forward(x).to(torch.float32)\n",
    "model.lm_head=CastOutputToFloat(model.lm_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settuping the Lora Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params=0\n",
    "    all_param=0\n",
    "    for _,param in model.named_parameters():\n",
    "        all_param+=param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params+=param.numel()\n",
    "        print(f\"trainable params:{trainable_params}||all params:{all_param}||trainable%:{100*trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig,get_peft_model\n",
    "config=LoraConfig(r=16,lora_alpha=32,lora_droput=0.05,bias=\"none\",task_type=\"CASUAL_LM\")\n",
    "model=get_peft_model(model,config)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from dataset import load_dataset\n",
    "data=load_dataset(\"Abirate/english_quote\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_columns(example):\n",
    "    example[\"prediction\"]=example[\"quote\"]+\"-->\"+str(example[\"tags\"])\n",
    "    return example\n",
    "\n",
    "data['train']=data['train'].map(merge_columns)\n",
    "data['train']['prediction'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.map(lambda samples:tokenizer(samples['prediction']),batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setuping the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=transformers.Trainer(model=model,train_dataset=data['train'],args=transformers.TrainingArguments(per_device_train_batch_size=4,gradient_accumulation_steps=4,warmup_steps=100,max_steps=200,learning_rate=2e-4,fp16=True,logging_steps=1,output_dir='outputs'),data_collector=transformer.DataCollatorForLanguageModeling(tokenizer,mlm=False))\n",
    "model.config.use_cache=False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the adapters on to the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(\"sample\",use_auth_toke=True,commit_message='basic training',private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load adapters from the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel,PeftConfig\n",
    "from transformers import AutoModelForCasualLLM,AutoTokenizer\n",
    "pet_model_id=\"samwit/bloom-7b-lora-tagger\"\n",
    "config=PeftConfig.from_pretrained(peft_model_id)\n",
    "tokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "## Loading the Lora Model\n",
    "model=PeftModel.from_pretrained(model,peft_model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=tokenizer(\"the world is an  oyster -->\",return_tensor='pt')\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens=model.generate(**batch,max_new_tokens=50)\n",
    "print('\\n \\n',tokenizer.decode(output_tokens[0],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=Us5ZFp16PaU"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
